{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b2f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994d58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa522e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1]])\n",
      "tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "context_size = 3\n",
    "\n",
    "def build_xy(words):\n",
    "    \"\"\"\n",
    "    Return X, Y tuple of training data and labels given words.\n",
    "\n",
    "    X will contain one row for each example. Each example will contain `context_size`\n",
    "    elements representing character indices.\n",
    "\n",
    "    Y will contain a character index label for each example.\n",
    "    \"\"\"\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for word in words:\n",
    "        context = [0] * context_size\n",
    "        for ch in word:\n",
    "            ich = stoi[ch]\n",
    "            xs.append(context)\n",
    "            ys.append(ich)\n",
    "            context = context[1:] + [ich]\n",
    "        xs.append(context)\n",
    "        ys.append(0)\n",
    "    assert len(xs) == len(ys)\n",
    "    X = torch.tensor(xs)\n",
    "    Y = torch.tensor(ys)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = build_xy(words[:1])\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a686617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_examples = Y.shape[0]\n",
    "\n",
    "# Number of characters in our alphabet (the very first one is the terminator character).\n",
    "vocab_size = 27\n",
    "\n",
    "# Number of dimensions in vector space that we map each character to.\n",
    "embedding_dims = 2\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, embedding_dims), dtype=torch.float, generator=g)\n",
    "C_lookup = C[X].view(num_examples, context_size * embedding_dims)\n",
    "\n",
    "# Make sure the very first example's first context item is the terminator character.\n",
    "terminator = C[0]\n",
    "assert C_lookup[0][:embedding_dims].tolist() == terminator.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da80ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
